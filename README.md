# Parameter Efficient Transfer Learning
Inspired by a paper ["Parameter-Efficient Transfer Learning for NLP"](https://arxiv.org/abs/1902.00751). It's an attempt to apply the described approach for a transformer-based pretrained model.



In my example, I take HuggingFace implementation of a Roberta model and do monkey patch.
